{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8052d641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 답변 파일 생성(sample_submission.csv)\n",
    "# llm 변경후 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57e419ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>src</th>\n",
       "      <th>content</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>ae28101b-a42e-45b7-b24b-4ea0f1fb2d50</td>\n",
       "      <td>ko_ai2_arc__ARC_Challenge__train</td>\n",
       "      <td>비뇨기계와 순환계는 혈액이 신장을 통과하면서 폐기물과 물이 제거될 때 관여하는 두 ...</td>\n",
       "      <td>비뇨기계와 순환계는 혈액이 신장을 통과하면서 폐기물과 물이 제거될 때 관여하는 두 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>eb727a4f-29c7-4d0c-b364-0e67de1776e9</td>\n",
       "      <td>ko_ai2_arc__ARC_Challenge__train</td>\n",
       "      <td>로봇은 현대 산업에서 많은 역할을 수행할 수 있습니다. 그러나 로봇 사용의 중대한 ...</td>\n",
       "      <td>로봇은 현대 산업에서 많은 역할을 수행할 수 있습니다. 그러나 로봇 사용의 중대한 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>0c8c0086-c377-4201-81fa-25159e5435a7</td>\n",
       "      <td>ko_mmlu__human_sexuality__test</td>\n",
       "      <td>월경은 여성의 생리주기에 따라 발생하는 현상으로, 에스트로겐과 프로게스테론 수치의 ...</td>\n",
       "      <td>월경은 여성의 생리주기에 따라 발생하는 현상으로, 에스트로겐과 프로게스테론 수치의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>06da6a19-ec78-404e-9640-9fc33f63c6a2</td>\n",
       "      <td>ko_ai2_arc__ARC_Challenge__train</td>\n",
       "      <td>식물이 내뿜는 가스는 산소입니다. 식물은 광합성 과정을 통해 태양 에너지를 이용하여...</td>\n",
       "      <td>식물이 내뿜는 가스는 산소입니다. 식물은 광합성 과정을 통해 태양 에너지를 이용하여...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271</th>\n",
       "      <td>03c36d5e-c711-4dc2-b4db-aaeb94d86395</td>\n",
       "      <td>ko_mmlu__computer_security__test</td>\n",
       "      <td>버퍼 오버런은 개발자들이 만든 널리 퍼져 있는 앱의 코딩 오류로써, 공격자가 시스템...</td>\n",
       "      <td>버퍼 오버런은 개발자들이 만든 널리 퍼져 있는 앱의 코딩 오류로써, 공격자가 시스템...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     docid                               src  \\\n",
       "4267  ae28101b-a42e-45b7-b24b-4ea0f1fb2d50  ko_ai2_arc__ARC_Challenge__train   \n",
       "4268  eb727a4f-29c7-4d0c-b364-0e67de1776e9  ko_ai2_arc__ARC_Challenge__train   \n",
       "4269  0c8c0086-c377-4201-81fa-25159e5435a7    ko_mmlu__human_sexuality__test   \n",
       "4270  06da6a19-ec78-404e-9640-9fc33f63c6a2  ko_ai2_arc__ARC_Challenge__train   \n",
       "4271  03c36d5e-c711-4dc2-b4db-aaeb94d86395  ko_mmlu__computer_security__test   \n",
       "\n",
       "                                                content  \\\n",
       "4267  비뇨기계와 순환계는 혈액이 신장을 통과하면서 폐기물과 물이 제거될 때 관여하는 두 ...   \n",
       "4268  로봇은 현대 산업에서 많은 역할을 수행할 수 있습니다. 그러나 로봇 사용의 중대한 ...   \n",
       "4269  월경은 여성의 생리주기에 따라 발생하는 현상으로, 에스트로겐과 프로게스테론 수치의 ...   \n",
       "4270  식물이 내뿜는 가스는 산소입니다. 식물은 광합성 과정을 통해 태양 에너지를 이용하여...   \n",
       "4271  버퍼 오버런은 개발자들이 만든 널리 퍼져 있는 앱의 코딩 오류로써, 공격자가 시스템...   \n",
       "\n",
       "                                                summary  \n",
       "4267  비뇨기계와 순환계는 혈액이 신장을 통과하면서 폐기물과 물이 제거될 때 관여하는 두 ...  \n",
       "4268  로봇은 현대 산업에서 많은 역할을 수행할 수 있습니다. 그러나 로봇 사용의 중대한 ...  \n",
       "4269  월경은 여성의 생리주기에 따라 발생하는 현상으로, 에스트로겐과 프로게스테론 수치의 ...  \n",
       "4270  식물이 내뿜는 가스는 산소입니다. 식물은 광합성 과정을 통해 태양 에너지를 이용하여...  \n",
       "4271  버퍼 오버런은 개발자들이 만든 널리 퍼져 있는 앱의 코딩 오류로써, 공격자가 시스템...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 1. 데이터 파일 읽기\n",
    "# import pandas as pd\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# df = pd.read_csv(\"./data/summary_one.csv\")\n",
    "# df.tail()\n",
    "\n",
    "\n",
    "# 1. 데이터 파일 읽기 (documents.jsonl)\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# .jsonl 파일을 읽기 위해 read_json 사용 (lines=True 옵션 필수)\n",
    "df = pd.read_json(\"../korea202/data/documents.jsonl\", lines=True)\n",
    "\n",
    "# 기존 코드와의 호환성을 위해 content를 summary 열로 복사\n",
    "# 벡터 DB 생성 시 'summary' 열을 사용하기 때문입니다.\n",
    "df['summary'] = df['content']\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cf4af9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4272 entries, 0 to 4271\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   docid    4272 non-null   object\n",
      " 1   src      4272 non-null   object\n",
      " 2   content  4272 non-null   object\n",
      " 3   summary  4272 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 133.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# 2. 정보 확인\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4af36c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 디비 생성 클래스\n",
    "\n",
    "import faiss\n",
    "import torch\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "def create_empty_faiss(embeddings, use_cosine=True):\n",
    "    \"\"\"빈 FAISS 벡터스토어 생성\"\"\"\n",
    "    dimension = len(embeddings.embed_query(\"test\"))\n",
    "    print(f\"dimension={dimension}\")\n",
    "    if use_cosine:\n",
    "        index = faiss.IndexFlatIP(dimension)\n",
    "        normalize = True\n",
    "    else:\n",
    "        index = faiss.IndexFlatL2(dimension)\n",
    "        normalize = False\n",
    "    \n",
    "    return FAISS(\n",
    "        embedding_function=embeddings,\n",
    "        index=index,\n",
    "        docstore=InMemoryDocstore(),\n",
    "        index_to_docstore_id={},\n",
    "        normalize_L2=normalize\n",
    "    )\n",
    "\n",
    "def get_embeddinggemma_300m(opt):\n",
    "    return HuggingFaceEmbeddings(\n",
    "        model_name=\"google/embeddinggemma-300m\",\n",
    "        encode_kwargs={\"prompt_name\": opt}\n",
    "    )\n",
    "\n",
    "def get_qwen3_embedding_4b():\n",
    "    return HuggingFaceEmbeddings(\n",
    "        model_name=\"Qwen/Qwen3-Embedding-4B\",\n",
    "        model_kwargs={\n",
    "            \"device\": \"cuda\"\n",
    "        },\n",
    "        encode_kwargs={\n",
    "            \"normalize_embeddings\": True\n",
    "        }\n",
    "    )\n",
    "\n",
    "class ScienceRAG:\n",
    "    def __init__(self):\n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "                                    model_name=\"BAAI/bge-m3\",\n",
    "                                    #model_name=\"Qwen/Qwen3-Embedding-0.6B\",\n",
    "                                    model_kwargs={\"device\": \"cuda\"} ,\n",
    "                                    encode_kwargs={\"normalize_embeddings\": True}) \n",
    "        \n",
    "        #self.embeddings = get_qwen3_embedding_4b()\n",
    "        \n",
    "        self.vectorstore = create_empty_faiss(self.embeddings, use_cosine=False) \n",
    "        \n",
    "    \n",
    "    def add_documents(self, df):\n",
    "        \"\"\"문서를 요약하여 벡터DB에 저장\"\"\"\n",
    "        \n",
    "        texts = df['summary'].tolist()\n",
    "        metadatas = [\n",
    "            {\n",
    "                'docid': row['docid'],\n",
    "                'content': row['content']\n",
    "            } \n",
    "            for _, row in df.iterrows()\n",
    "        ]\n",
    "        ids = df['docid'].tolist()\n",
    "\n",
    "\n",
    "        # 2. 검색용 요약을 벡터DB에 저장\n",
    "        self.vectorstore.add_texts(\n",
    "            texts,\n",
    "            metadatas=metadatas,\n",
    "            ids = ids\n",
    "        )\n",
    "        \n",
    "       \n",
    "    def search(self, query: str, k: int = 3):\n",
    "        \"\"\"요약된 내용으로 검색\"\"\"\n",
    "        results = self.vectorstore.similarity_search(query, k=k)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a10e62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1851406/299196106.py:47: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  self.embeddings = HuggingFaceEmbeddings(\n",
      "/opt/conda/envs/py311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension=1024\n"
     ]
    }
   ],
   "source": [
    "# 4. 디비 생성 \n",
    "\n",
    "science_rag = ScienceRAG()\n",
    "\n",
    "science_rag.add_documents(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2a8f5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='e2161953-e80b-41b3-a83b-5bc7d76a801c', metadata={'docid': 'e2161953-e80b-41b3-a83b-5bc7d76a801c', 'content': '공이 땅에서 굴러가고 있습니다. 이때, 공이 움직이는 방향과 같은 방향으로 힘이 공을 밀어줍니다. 이렇게 힘이 가해지면 공은 원래 움직이던 방향으로 더 빠르게 움직입니다. 이는 힘이 공에 가해져서 공의 운동에 영향을 주기 때문입니다. 힘은 질량에 가해지는 힘과 방향에 따라 운동에 영향을 줄 수 있습니다. 따라서, 공이 힘을 받으면 힘이 가해진 방향과 같은 방향으로 더 빠르게 움직이게 됩니다.'}, page_content='공이 땅에서 굴러가고 있습니다. 이때, 공이 움직이는 방향과 같은 방향으로 힘이 공을 밀어줍니다. 이렇게 힘이 가해지면 공은 원래 움직이던 방향으로 더 빠르게 움직입니다. 이는 힘이 공에 가해져서 공의 운동에 영향을 주기 때문입니다. 힘은 질량에 가해지는 힘과 방향에 따라 운동에 영향을 줄 수 있습니다. 따라서, 공이 힘을 받으면 힘이 가해진 방향과 같은 방향으로 더 빠르게 움직이게 됩니다.'),\n",
       "  np.float32(0.53543067)),\n",
       " (Document(id='a662feb5-e069-44d8-b148-4641039d2329', metadata={'docid': 'a662feb5-e069-44d8-b148-4641039d2329', 'content': '공을 공중에 직선으로 던져서 다시 내려올 때 공의 속도를 가장 알맞게 설명하는 것은 다음과 같습니다. 공은 올라갈수록 점점 느려지며, 멈춘 후, 내려올 때 점점 빨라집니다. 이는 중력의 영향으로 인해 발생하는 현상입니다. 중력은 공을 아래로 끌어당기는 힘으로, 공이 올라갈 때는 중력의 힘이 공의 운동에 반대 방향으로 작용하여 속도를 감소시킵니다. 그리고 공이 멈춘 후, 중력의 힘은 공을 아래로 끌어당기기 시작하여 공의 속도를 증가시킵니다. 이러한 과정을 통해 공은 올라갈수록 느려지고, 멈춘 후 내려올 때는 점점 빨라지는 것을 관찰할 수 있습니다. 이러한 현상은 우리 일상에서도 자주 볼 수 있는 현상 중 하나입니다.'}, page_content='공을 공중에 직선으로 던져서 다시 내려올 때 공의 속도를 가장 알맞게 설명하는 것은 다음과 같습니다. 공은 올라갈수록 점점 느려지며, 멈춘 후, 내려올 때 점점 빨라집니다. 이는 중력의 영향으로 인해 발생하는 현상입니다. 중력은 공을 아래로 끌어당기는 힘으로, 공이 올라갈 때는 중력의 힘이 공의 운동에 반대 방향으로 작용하여 속도를 감소시킵니다. 그리고 공이 멈춘 후, 중력의 힘은 공을 아래로 끌어당기기 시작하여 공의 속도를 증가시킵니다. 이러한 과정을 통해 공은 올라갈수록 느려지고, 멈춘 후 내려올 때는 점점 빨라지는 것을 관찰할 수 있습니다. 이러한 현상은 우리 일상에서도 자주 볼 수 있는 현상 중 하나입니다.'),\n",
       "  np.float32(0.6525155)),\n",
       " (Document(id='2107ea05-8350-45e8-b72f-19e99ed1256d', metadata={'docid': '2107ea05-8350-45e8-b72f-19e99ed1256d', 'content': '공이 아래로 던져져 콘크리트 바닥에서 튕겨 올라갑니다. 이는 바닥이 공에게 위로 향하는 힘을 제공하기 때문입니다. 바닥은 공이 떨어질 때 힘을 받아서 공을 튕겨 올립니다. 이 힘은 바닥의 탄력성과 관련이 있습니다. 바닥은 공이 떨어질 때 압력을 받아 압축되고, 그 압력을 통해 공에게 위로 향하는 힘을 전달합니다. 이러한 힘은 공이 튕겨서 오르게 만듭니다. 따라서, 바닥은 공이 튕겨서 오르게 하는 위로 향하는 힘을 제공합니다.'}, page_content='공이 아래로 던져져 콘크리트 바닥에서 튕겨 올라갑니다. 이는 바닥이 공에게 위로 향하는 힘을 제공하기 때문입니다. 바닥은 공이 떨어질 때 힘을 받아서 공을 튕겨 올립니다. 이 힘은 바닥의 탄력성과 관련이 있습니다. 바닥은 공이 떨어질 때 압력을 받아 압축되고, 그 압력을 통해 공에게 위로 향하는 힘을 전달합니다. 이러한 힘은 공이 튕겨서 오르게 만듭니다. 따라서, 바닥은 공이 튕겨서 오르게 하는 위로 향하는 힘을 제공합니다.'),\n",
       "  np.float32(0.6650251))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "query = \"공에 힘이 주어졌을 때 공이 어떻게 움직이는지 과학적으로 설명해줘.\"\n",
    "docs = science_rag.vectorstore.similarity_search_with_score(query, k=3)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55a0ba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 질의문 생성 체인\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"alibayram/Qwen3-30B-A3B-Instruct-2507\")\n",
    "\n",
    "# 프롬프트 \n",
    "convertFormat = \"\"\"\n",
    "당신은 문자열 포맷 마이그레이션 전문가 입니다. <message> 에서 content 내용만 문자열로 출력합니다. 만일 content가 여러개가 있으면 전체적인 문맥을 파악하여 질문을 만들어서 출력합니다.\n",
    "\n",
    "<message>\n",
    "{message}\n",
    "</message>\n",
    "\n",
    "[example]\n",
    "\n",
    "    <message>{{\"role\": \"user\", \"content\": \"피를 맑게 하고 몸 속의 노폐물을 없애는 역할을 하는 기관은?\"}}</message> \n",
    "    output:피를 맑게 하고 몸 속의 노폐물을 없애는 역할을 하는 기관은? \n",
    "\n",
    "    <message>{{\"role\": \"user\", \"content\": \"이란 콘트라 사건이 뭐야\"}}, {{\"role\": \"assistant\", \"content\": \"이란-콘트라 사건은 로널드 레이건 집권기인 1986년에 레이건 행정부와 CIA가 적성국이었던 이란에게 무기를 몰래 수출한 대금으로 니카라과의 우익 성향 반군 콘트라를 지원하면서 동시에 반군으로부터 마약을 사들인 후 미국에 판매하다가 발각되어 큰 파장을 일으킨 사건입니다.\"}}, {{\"role\": \"user\", \"content\": \"이 사건이 미국 정치에 미친 영향은?\"}}</message>\n",
    "    output:1986년에 발생한 이란 콘트라 사건이 미국 정치에 미친 영향은? \n",
    "\n",
    "\n",
    "output:\n",
    "[Your output here - NOTHING ELSE]\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 객체 생성\n",
    "convertFormat_prompt = PromptTemplate(\n",
    "    input_variables=[\"message\"],\n",
    "    template=convertFormat\n",
    ")\n",
    "\n",
    "# 출력 파서 (문자열)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# LCEL 체인 구성\n",
    "convertFormat_chain = (\n",
    "    convertFormat_prompt \n",
    "    | llm \n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fc1bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 과학상식 체크 체인\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "# 프롬프트 \n",
    "selectYn = \"\"\"\n",
    "당신은 세상의 모든 상식과 지식에 정통한 전문가 입니다. 만약 <message> 가 세상의 상식 또는 지식에 관련된 질문이라면  Y 아니라면 N으로 답해주세요. 너에 관하여 물어보는건 세상의 상식 또는 지식에 관련된 질문이 아니야!\n",
    "\n",
    "<message>\n",
    "{message}\n",
    "</message>\n",
    "\n",
    "당신은 반드시 Y 뜨는 N으로 답해야 합니다.\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 객체 생성\n",
    "selectYn_prompt = PromptTemplate(\n",
    "    input_variables=[\"message\"],\n",
    "    template=selectYn\n",
    ")\n",
    "\n",
    "# 출력 파서 (문자열)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# LCEL 체인 구성\n",
    "selectYn_chain = (\n",
    "    selectYn_prompt \n",
    "    | llm \n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9013aceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 답변 생성 체인\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "# 프롬프트 \n",
    "answer = \"\"\"\n",
    "당신은 과학 상식 전문가 입니다. <message> 의 질문에 대해서 주어진 <reference> 정보를 활용하여 간결하게 답변을 생성합니다.\n",
    "\n",
    "    - 주어진 검색 결과 정보로 대답할 수 없는 경우는 정보가 부족해서 답을 할 수 없다고 대답합니다.\n",
    "    - 한국어로 답변을 생성합니다..\n",
    "\n",
    "<message>\n",
    "{message}\n",
    "</message>\n",
    "\n",
    "<reference>\n",
    "{reference}\n",
    "</reference>\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 객체 생성\n",
    "answer_prompt = PromptTemplate(\n",
    "    input_variables=[\"message\"],\n",
    "    template=answer\n",
    ")\n",
    "\n",
    "# 출력 파서 (문자열)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# LCEL 체인 구성\n",
    "answer_chain = (\n",
    "    answer_prompt \n",
    "    | llm \n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "420e6d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-1. 리랭커 모델 로드 (새로운 셀 추가)\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# 한국어 리랭킹에 성능이 좋은 모델을 로드합니다.\n",
    "reranker_model = CrossEncoder('BAAI/bge-reranker-v2-m3', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f5c2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 8. 데이터 검색 함수\n",
    "\n",
    "# def query_db(message):\n",
    "\n",
    "#     docs = science_rag.vectorstore.similarity_search_with_relevance_scores(message, k=3)\n",
    "\n",
    "#     #filtered_docs = []\n",
    "#     content = []\n",
    "#     docid= []\n",
    "#     reference = []\n",
    "    \n",
    "#     for doc, score in docs:\n",
    "#         content.append(doc.metadata['content'])\n",
    "#         docid.append(doc.metadata['docid'])\n",
    "#         reference.append({\"score\": float(score), \"content\": doc.metadata['content']})\n",
    "#     return content, docid, reference\n",
    "\n",
    "# 8. 데이터 검색 함수 (리랭킹 적용)\n",
    "\n",
    "def query_db(message):\n",
    "    \n",
    "    # 1. 1차 검색(Retrieval): 리랭킹을 위해 후보군을 더 많이 가져옵니다 (예: k=10)\n",
    "    retrieved_docs = science_rag.vectorstore.similarity_search_with_relevance_scores(message, k=40)\n",
    "\n",
    "    # 2. 리랭킹(Re-ranking)\n",
    "    # 리랭커의 입력 형식에 맞게 [질문, 문서] 쌍을 생성합니다.\n",
    "    rerank_input_pairs = [[message, doc.page_content] for doc, score in retrieved_docs]\n",
    "    \n",
    "    # 리랭커 모델로 새로운 점수를 계산합니다.\n",
    "    rerank_scores = reranker_model.predict(rerank_input_pairs)\n",
    "\n",
    "    # 3. 새로운 점수와 기존 문서를 결합하여 정렬\n",
    "    reranked_results = []\n",
    "    for i, (doc, score) in enumerate(retrieved_docs):\n",
    "        reranked_results.append({\n",
    "            'doc': doc,\n",
    "            'original_score': score,\n",
    "            'rerank_score': rerank_scores[i]\n",
    "        })\n",
    "    \n",
    "    # 리랭킹 점수(rerank_score)를 기준으로 내림차순 정렬\n",
    "    reranked_results.sort(key=lambda x: x['rerank_score'], reverse=True)\n",
    "\n",
    "    # 4. 최종 결과 선택: 리랭킹 후 상위 3개 문서를 선택\n",
    "    final_docs = reranked_results[:3]\n",
    "\n",
    "    # 5. 최종 결과 포맷팅 (기존 코드와 동일한 출력 형식 유지)\n",
    "    content = []\n",
    "    docid = []\n",
    "    reference = []\n",
    "    \n",
    "    for result in final_docs:\n",
    "        doc = result['doc']\n",
    "        # reference에는 리랭킹된 점수를 넣어주는 것이 더 정확합니다.\n",
    "        rerank_score = result['rerank_score']\n",
    "        \n",
    "        content.append(doc.metadata['content'])\n",
    "        docid.append(doc.metadata['docid'])\n",
    "        reference.append({\"score\": float(rerank_score), \"content\": doc.metadata['content']})\n",
    "        \n",
    "    return content, docid, reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77380f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "message = convertFormat_chain.invoke({\"message\": '{\"role\": \"user\", \"content\": \"python 공부중인데...\"}, {\"role\": \"assistant\", \"content\": \"네 꼭 필요한 언어라서 공부해 두면 좋습니다.\"}, {\"role\": \"user\", \"content\": \"숫자 계산을 위한 operator 우선순위에 대해 알려줘.\"}'})\n",
    "print(message)\n",
    "result = selectYn_chain.invoke({\"message\": \"니가 대답을 잘해줘서 너무 신나!\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339542df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "import json\n",
    "\n",
    "with open(\"../korea202/data/eval.jsonl\") as f:\n",
    "   for line in f:\n",
    "\n",
    "            j = json.loads(line)\n",
    "            message = convertFormat_chain.invoke({\"message\": j[\"msg\"]})\n",
    "            print(f'{message}:{len(message)}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac10f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "content, docid, reference = query_db(\"세제의 거품이 만들어지는 원리는?\")\n",
    "print(content)\n",
    "print(docid)\n",
    "print(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f8c8da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. 메인 로직\n",
    "\n",
    "import json\n",
    "\n",
    "# 답변 데이터 생성\n",
    "def answer_question(messages):\n",
    "    # 함수 출력 초기화\n",
    "    response = {\"standalone_query\": \"\", \"topk\": [], \"references\": [], \"answer\": \"\"}\n",
    "\n",
    "    message = convertFormat_chain.invoke({\"message\": messages})\n",
    "    result = selectYn_chain.invoke({\"message\": message})\n",
    "\n",
    "    context = {\"message\":message}\n",
    "\n",
    "    if result == \"Y\":\n",
    "        context[\"reference\"], response[\"topk\"], response[\"references\"] = query_db(message)\n",
    "    else:\n",
    "        context[\"reference\"] = \"\"\n",
    "        response[\"topk\"] = []\n",
    "        response[\"references\"] = []\n",
    "    \n",
    "    response[\"answer\"] = answer_chain.invoke(context)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "# 답변 저장\n",
    "def eval_rag(eval_filename, output_filename):\n",
    "    with open(eval_filename) as f, open(output_filename, \"w\") as of:\n",
    "        idx = 0\n",
    "        for line in f:\n",
    "\n",
    "            #if idx == 10: break\n",
    "            \n",
    "            j = json.loads(line)\n",
    "            print(f'Test {idx}\\nQuestion: {j[\"msg\"]}')\n",
    "            response = answer_question(j[\"msg\"])\n",
    "            print(f'Answer: {response[\"answer\"]}\\n')\n",
    "\n",
    "            # 대회 score 계산은 topk 정보를 사용, answer 정보는 LLM을 통한 자동평가시 활용\n",
    "            output = {\"eval_id\": j[\"eval_id\"], \"standalone_query\": response[\"standalone_query\"], \"topk\": response[\"topk\"], \"answer\": response[\"answer\"], \"references\": response[\"references\"]}\n",
    "            of.write(f'{json.dumps(output, ensure_ascii=False)}\\n')\n",
    "            idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdec5a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 0\n",
      "Question: [{'role': 'user', 'content': '나무의 분류에 대해 조사해 보기 위한 방법은?'}]\n",
      "Answer: 나무의 분류를 조사하기 위해서는 먼저 나무의 생물학적 특징을 관찰하는 것이 중요합니다. 성장 속도, 크기, 온도 범위 등 외형적 특징을 비교하고, 특히 잎과 꽃 등의 구조적 특징을 세밀히 분석해야 합니다. 또한 현대 생물학에서는 유전자나 단백질의 분자 수준에서의 분석을 통해 진화적 관계를 파악함으로써 더 정확한 분류를 할 수 있습니다. 따라서 나무의 분류 조사를 위해서는 구조적 특징과 분자 생물학적 분석을 병행하는 것이 효과적입니다.\n",
      "\n",
      "Test 1\n",
      "Question: [{'role': 'user', 'content': '각 나라에서의 공교육 지출 현황에 대해 알려줘.'}]\n",
      "Answer: 주어진 정보에서는 각 나라의 공교육 지출 현황에 대한 구체적인 수치나 비교 데이터가 포함되어 있지 않으며, 전세계 공공 교육 지출이 세계 GDP의 약 4%를 차지한다는 전반적인 정보만 제공됩니다. 따라서 각 나라별 공교육 지출 현황에 대한 구체적인 답변을 드릴 수 없습니다.\n",
      "\n",
      "Test 2\n",
      "Question: [{'role': 'user', 'content': '기억 상실증 걸리면 너무 무섭겠다.'}, {'role': 'assistant', 'content': '네 맞습니다.'}, {'role': 'user', 'content': '어떤 원인 때문에 발생하는지 궁금해.'}]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 10. 메인 \u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 평가 데이터에 대해서 결과 생성 - 파일 포맷은 jsonl이지만 파일명은 csv 사용\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43meval_rag\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../korea202/data/eval.jsonl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./data/sample_submission.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36meval_rag\u001b[39m\u001b[34m(eval_filename, output_filename)\u001b[39m\n\u001b[32m     35\u001b[39m j = json.loads(line)\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mTest \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mQuestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj[\u001b[33m\"\u001b[39m\u001b[33mmsg\u001b[39m\u001b[33m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m response = \u001b[43manswer_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmsg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAnswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse[\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# 대회 score 계산은 topk 정보를 사용, answer 정보는 LLM을 통한 자동평가시 활용\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36manswer_question\u001b[39m\u001b[34m(messages)\u001b[39m\n\u001b[32m     13\u001b[39m context = {\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m:message}\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result == \u001b[33m\"\u001b[39m\u001b[33mY\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     context[\u001b[33m\"\u001b[39m\u001b[33mreference\u001b[39m\u001b[33m\"\u001b[39m], response[\u001b[33m\"\u001b[39m\u001b[33mtopk\u001b[39m\u001b[33m\"\u001b[39m], response[\u001b[33m\"\u001b[39m\u001b[33mreferences\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mquery_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     18\u001b[39m     context[\u001b[33m\"\u001b[39m\u001b[33mreference\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mquery_db\u001b[39m\u001b[34m(message)\u001b[39m\n\u001b[32m     27\u001b[39m rerank_input_pairs = [[message, doc.page_content] \u001b[38;5;28;01mfor\u001b[39;00m doc, score \u001b[38;5;129;01min\u001b[39;00m retrieved_docs]\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# 리랭커 모델로 새로운 점수를 계산합니다.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m rerank_scores = \u001b[43mreranker_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrerank_input_pairs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# 3. 새로운 점수와 기존 문서를 결합하여 정렬\u001b[39;00m\n\u001b[32m     33\u001b[39m reranked_results = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/py311/lib/python3.11/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/py311/lib/python3.11/site-packages/sentence_transformers/cross_encoder/util.py:68\u001b[39m, in \u001b[36mcross_encoder_predict_rank_args_decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m         kwargs.pop(deprecated_arg)\n\u001b[32m     64\u001b[39m         logger.warning(\n\u001b[32m     65\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe CrossEncoder.predict `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeprecated_arg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` argument is deprecated and has no effect. It will be removed in a future version.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     66\u001b[39m         )\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/py311/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:464\u001b[39m, in \u001b[36mCrossEncoder.predict\u001b[39m\u001b[34m(self, sentences, batch_size, show_progress_bar, activation_fn, apply_softmax, convert_to_numpy, convert_to_tensor)\u001b[39m\n\u001b[32m    457\u001b[39m batch = sentences[start_index : start_index + batch_size]\n\u001b[32m    458\u001b[39m features = \u001b[38;5;28mself\u001b[39m.tokenizer(\n\u001b[32m    459\u001b[39m     batch,\n\u001b[32m    460\u001b[39m     padding=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    461\u001b[39m     truncation=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    462\u001b[39m     return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    463\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m \u001b[43mfeatures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m model_predictions = \u001b[38;5;28mself\u001b[39m.model(**features, return_dict=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    466\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.activation_fn(model_predictions.logits)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/py311/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:818\u001b[39m, in \u001b[36mBatchEncoding.to\u001b[39m\u001b[34m(self, device)\u001b[39m\n\u001b[32m    814\u001b[39m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[32m    815\u001b[39m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[32m    816\u001b[39m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[32m    817\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m818\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = \u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    819\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    820\u001b[39m     logger.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. This is not supported.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/py311/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:818\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    814\u001b[39m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[32m    815\u001b[39m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[32m    816\u001b[39m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[32m    817\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m818\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = {k: \u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.data.items() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, torch.Tensor)}\n\u001b[32m    819\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    820\u001b[39m     logger.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. This is not supported.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 10. 메인 \n",
    "\n",
    "# 평가 데이터에 대해서 결과 생성 - 파일 포맷은 jsonl이지만 파일명은 csv 사용\n",
    "eval_rag(\"../korea202/data/eval.jsonl\", \"./data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c24677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
